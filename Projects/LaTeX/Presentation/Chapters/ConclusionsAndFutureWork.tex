\setlength{\parskip}{\baselineskip}
\section{Conclusion}

\begin{frame}
	\huge Conclusions \& Future Work
\end{frame}

\begin{frame}{Conclusions}
	\begin{itemize}
		\item Neural Networks need hardware acceleration
		\item Proposed platform provides an easy and structured methodology for scalable \& expandable accelerator implementation
		\item Memory reduction is a necessity
		\item Further development $\rightarrow$ higher performance
	\end{itemize}
\end{frame}

\begin{frame}{Future Work}
	\begin{itemize}
		\item Quantization: better classification accuracy, K-Means clustering, Lloyd's, Pair and Quad compression, and Second Level Codebook
		\item Integrating the pooling layer into the convolution layer
		\item Pruning enabled accelerators
		\item Systolic arrays as their main compute engine
		\item Multiple accelerator instances
	\end{itemize}
\end{frame}

\begin{frame}{Future Work}
	\begin{itemize}
		\item Layer-Pipelining
		\item Bigger FPGA devices \& multiple interconnected FPGAs (FORTH QFDB \& CRDB).
		\item Monte Carlo Dropout for increased confidence of classification results
		\item Designs using VHDL \& Verilog for resource \& performance optimization
		\item CPU-FPGA partitioning
	\end{itemize}
\end{frame}
